{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish_EXP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "#Libaries for calculation and processing\n",
    "from einops import rearrange, repeat\n",
    "import math\n",
    "from math import sqrt\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#libaries for data importng, formating and handling \n",
    "import pandas as pd\n",
    "#For analysis and plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#others\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from model.Crossformer import *\n",
    "from data.Dataset import Dataset_MTS,Dataset_MTS_simplified\n",
    "from exp.ExpFish import Expfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DATASET \n",
    "ROOT_PATH = \"data/DatasetClusters/fishes/fish02/\"\n",
    "DATA_PATH = \"s1/df_timeseries_red_clusters_s1.csv\"\n",
    "TRAIN_FLAG = \"train\"\n",
    "VAL_FLAG = \"val\"\n",
    "TEST_FLAG = \"test\"\n",
    "SIZE=[50,50,50] #[seq_len, label_len, pred_len]\n",
    "SCALE = True\n",
    "SCALE_STATISTIC = True\n",
    "DATA_SPLIT = [1, 0, 0.0]  # Train, Val, TEST\n",
    "STRIDE = 1\n",
    "\n",
    "#DATALOADER \n",
    "BATCH_SIZE = 10\n",
    "SHUFFLE_FLAG = False\n",
    "NUM_WORKSES = 0\n",
    "DROP_LAST = False\n",
    "\n",
    "#MODEL \n",
    "DATA_DIM = 2 # number of clusers\n",
    "IN_LEN   = SIZE[0]\n",
    "OUT_LEN  = SIZE[2]\n",
    "SEG_LEN  = 10\n",
    "WIN_SIZE = 1\n",
    "FACTOR   = 2\n",
    "D_MODEL  = 256 \n",
    "D_FF     = 512\n",
    "N_HEADS  = 1\n",
    "E_LAYERS = 1\n",
    "DROPOUT  = 0.2\n",
    "BASELINE = False\n",
    "\n",
    "#Device\n",
    "DEVICE   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#OPTIMIZER\n",
    "LR = 0.001\n",
    "\n",
    "#TRAINING \n",
    "NUM_EPOCHS = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset_MTS(root_path=ROOT_PATH,data_path=DATA_PATH,flag=TRAIN_FLAG,size=SIZE,scale=SCALE,scale_statistic=SCALE_STATISTIC,data_split=DATA_SPLIT,stride=STRIDE)\n",
    "\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "            train_set,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=SHUFFLE_FLAG,\n",
    "            num_workers=NUM_WORKSES,\n",
    "            drop_last=DROP_LAST\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Crossformer(\n",
    "    data_dim=DATA_DIM,\n",
    "    in_len=IN_LEN,\n",
    "    out_len=OUT_LEN,\n",
    "    seg_len=SEG_LEN,\n",
    "    win_size=WIN_SIZE,\n",
    "    factor=FACTOR,\n",
    "    d_model=D_MODEL,\n",
    "    d_ff=D_MODEL,\n",
    "    n_heads=N_HEADS,\n",
    "    e_layers=E_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    baseline=False,\n",
    "    device=DEVICE\n",
    "    \n",
    ").float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss-function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 6.283841848373413\n",
      "Epoch: 1, Steps: 94 | Train Loss: 0.9975803 Vali Loss: 0.0000000\n",
      "Epoch: 2 cost time: 5.832176446914673\n",
      "Epoch: 2, Steps: 94 | Train Loss: 1.1206553 Vali Loss: 0.0000000\n"
     ]
    }
   ],
   "source": [
    "exp = Expfish(model=model,\n",
    "               data_loader_train=data_loader_train,\n",
    "               data_loader_test=None,\n",
    "               data_loader_val=None,\n",
    "               optimizer=optimizer,\n",
    "               criterion=criterion,\n",
    "               num_epochs=NUM_EPOCHS,\n",
    "               device=DEVICE\n",
    "               \n",
    "               )\n",
    "\n",
    "model = exp.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proMaster2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
